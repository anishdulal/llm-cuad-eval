# LLMâ€‘CUADâ€‘EVAL

Fineâ€‘tune and evaluate **largeâ€‘language models (LLMs)** on the **CUAD â€“ Contract Understanding Atticus Dataset**.  
The project focuses on **Llamaâ€¯3.2â€¯(3B parameters)** but the intention is to evaluate more models(open as well as paid) in the future.

---

## ğŸ“¦ Repository layout

| Path / file                              | What it is                                                       |
| ---------------------------------------- | ---------------------------------------------------------------- |
| `finetune.py`                            | Endâ€‘toâ€‘end fineâ€‘tuning script (LoRAÂ + 4â€‘bit) for 10â€¯k CUAD train examples |
| `evaluate.py`                            | Exactâ€‘Match / F1 scorer for **original vs. fineâ€‘tuned** checkpoints |
| `finetune_evaluate_colab.ipynb`          | Colab Pro notebook that reproduces both scripts on an A100â€¯40â€¯GB |
| `get_claude_answers.py`                  | Script for evaluating Claude models(not completed) |
| `requirements.txt`                       | All Python dependencies |
| `assets/finetune_loss_curve.png`         |  PNG of training loss curve |
| `LICENSE`                                | MIT license |

---

## ğŸ”§ Requirements

All dependencies are gathered in **`requirements.txt`** â€“ they are the exact versions the scripts were developed with.  
*Key libraries:* `PyTorch`, `transformers`, `datasets`, `unsloth`, `bitsandbytes`, `accelerate`.

---

## ğŸš€ Quick start

> **Tip:** Use Pythonâ€¯3.9â€¯/â€¯3.10 and a GPU with â‰¥â€¯40â€¯GB VRAM for training.  
> Evaluation will also run on smaller GPUs or CPU (slow).

```bash
# clone & enter
git clone https://github.com/<yourâ€‘user>/llm-cuad-eval.git
cd llm-cuad-eval

# optional â€“ create a clean venv
python -m venv .venv && source .venv/bin/activate

# install everything
pip install -r requirements.txt
````

### 1. Fineâ€‘tune Llamaâ€¯3â€¯3B on CUAD

```bash
python finetune.py
```

*The script handles:*

* downloading `unsloth/Llama-3.2-3B-Instruct-bnb-4bit`
* downloading **10â€¯000** train examples from CUAD
  (the code fetches the dataset automatically â€“ no manual download)
* training a 65â€¯kâ€‘token LoRA adapter
  (\~â€¯780â€¯min on a single NVIDIAÂ A100â€¯40â€¯GB)
* LoRA (0.81 % of weights trainable) + 4-bit quantization
* Trains **1 250 steps** (batch size 2 Ã— grad\_accum 4 = 8 effective)

Outputs are written to `./cuad_finetuned_llama3_2_3b/`.

### 2. Evaluate

```bash
python evaluate.py \
  --model_path unsloth/Llama-3.2-3B-Instruct-bnb-4bit \
  --finetuned_model_path ./cuad_finetuned_llama3_2_3b \
  --split test
```

By default the script scores **both** checkpoints on the full CUAD test set (4â€¯182 samples).
See `--help` for all CLI flags (sequence length, output dir, etc.).

### 3. (Optional) run everything on Colab

1. Open **`finetune_evaluate_colab.ipynb`** in GoogleÂ Colabâ€¯Pro/Pro+
2. Select **GPUâ€¯â†’â€¯A100â€¯(40â€¯GB)**
3. Run all cells â€“ thatâ€™s it.

---

## ğŸ“Š Results

| Model (3B)                                          | ExactÂ Match |      F1 | Samples | TimeÂ (min) | SpeedÂ (sps) |
| --------------------------------------------------- | ----------: | ------: | ------: | ---------: | ----------: |
| *Original*Â `unsloth/Llama-3.2-3B-Instruct-bnb-4bit` | **27.14â€¯%** | 32.24â€¯% |   4â€¯182 |     167.00 |        0.42 |
| *Fineâ€‘tuned*Â `./cuad_finetuned_llama3_2_3b`         | **74.06â€¯%** | 75.95â€¯% |   4â€¯182 |      60.15 |        1.16 |

**Î” Improvement**

* Exactâ€‘Match: **+46.92â€¯pp**
* F1: **+43.71â€¯pp**

---

## ğŸ” Qualitative examples (before â†’ after)

<details>
<summary>Click to expand</summary>

```jsonc
// BEFORE FINETUNING
{
  "id": "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Document Name",
  "question": "Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract",
  "context_length": 11475,
  "ground_truths": [
    "SUPPLY CONTRACT"
  ],
  "prediction": "Contract Name: 12. Documents",
  "exact_match": 0,
  "f1_score": 0.3333333333333333
},
{
  "id": "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Parties",
  "question": "Highlight the parts (if any) of this contract related to \"Parties\" that should be reviewed by a lawyer. Details: The two or more parties who signed the contract",
  "context_length": 11475,
  "ground_truths": [
    "The seller:"
  ],
  "prediction": "All of contract.",
  "exact_match": 0,
  "f1_score": 0.0
},
{
  "id": "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Agreement Date",
  "question": "Highlight the parts (if any) of this contract related to \"Agreement Date\" that should be reviewed by a lawyer. Details: The date of the contract",
  "context_length": 11475,
  "ground_truths": [
    "Not found"
  ],
  "prediction": "The buyer entrust the entrusted party to purchase the products specified in this agreement from the seller in the form of orders.",
  "exact_match": 0,
  "f1_score": 0.0
}

// AFTER FINETUNING
{
  "id": "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Document Name",
  "question": "Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract",
  "context_length": 11475,
  "ground_truths": [
    "SUPPLY CONTRACT"
  ],
  "prediction": "SUPPLY CONTRACT",
  "exact_match": 1,
  "f1_score": 1.0
},
{
  "id": "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Parties",
  "question": "Highlight the parts (if any) of this contract related to \"Parties\" that should be reviewed by a lawyer. Details: The two or more parties who signed the contract",
  "context_length": 11475,
  "ground_truths": [
    "The seller:"
  ],
  "prediction": "Seller",
  "exact_match": 1,
  "f1_score": 1.0
},
{
  "id": "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Agreement Date",
  "question": "Highlight the parts (if any) of this contract related to \"Agreement Date\" that should be reviewed by a lawyer. Details: The date of the contract",
  "context_length": 11475,
  "ground_truths": [
    "Not found"
  ],
  "prediction": "Not found",
  "exact_match": 1,
  "f1_score": 1.0
}

// Claude Haiku 3
{
  "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Document Name": "The following phrases from the contract relate to \"Document Name\" that should be reviewed by a lawyer:\n\n\"12.1 (1) Invoice in 5 originals indicating contract number and Shipping Mark (in case of more than one shipping mark, the invoice shall be issued separately).\"\n\n\"12",
  "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Parties": "The relevant parts related to the \"Parties\" that should be reviewed by a lawyer are:\n\n1.1 \"This is a framework agreement, the terms and conditions are applied to all purchase orders which signed by this agreement (hereinafter referred to as the \"order\").\"\n\n2.1 \"",
  "LohaCompanyltd_20191209_F-1_EX-10.16_11917878_EX-10.16_Supply Agreement__Agreement Date": "The following phrases from the contract are related to the agreement date and should be reviewed by a lawyer:\n\n\"The Contract is concluded and signed by the Buyer and Seller on , in Hong Kong.\"\n\n\"This Contract is valid for 5 years, beginning from and ended on .\""
}
```


</details>

---

## ğŸ“ˆ Training curve

![Finetune loss](assets/finetune_loss_curve.png)

---

## ğŸ¤ Acknowledgements

* **CUAD** â€“ the Contract Understanding Atticus Dataset
* **Unsloth** â€“ fast parameterâ€‘efficient fineâ€‘tuning library
* **HuggingÂ Face ecosystem** â€“ `transformers`, `datasets`, `peft`, etc.

---

## ğŸ“œ License

Released under the MIT License â€“ see [`LICENSE`](LICENSE) for details.

